{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitbaseconda6a1770027b924823bf65f396110ad90f",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "bc4fbd6e1bea1fda9411923f753f92d3282c070fdbd959891bf5a78b35520a26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "\n",
    "class Datapoint():\n",
    "    def __init__(self, km, price):\n",
    "        self.km = km\n",
    "        self.price = price\n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "        return (f\"km: {self.km}, price {self.price}\")\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (f\"km: {self.km}, price {self.price}\")\n",
    "\n",
    "class Dataset():\n",
    "    def __init__(self, path, standardize = True):\n",
    "        self.data = None\n",
    "        self.i = -1\n",
    "        try:\n",
    "            self.read_csv(path)\n",
    "        except Exception as e:\n",
    "            print(f\"Please give a valid input, only numeric data is accepted\\n{e}\")\n",
    "            raise ValueError\n",
    "        self.standardized = False\n",
    "        if (self.standardize):\n",
    "            self.standardize()\n",
    "        self.add_ones_to_x()\n",
    "\n",
    "\n",
    "    def destandardize(self):\n",
    "        self.x[:,1:] = self.x_scaler.inverse_transform(self.x[:,1:])\n",
    "        self.y = self.y_scaler.inverse_transform(self.y[:, np.newaxis])\n",
    "        self.y = np.reshape(self.y, self.y.shape[0])\n",
    "\n",
    "\n",
    "    def standardize(self):\n",
    "        self.standardized = True\n",
    "        self.x_scaler = StandardScaler()\n",
    "        self.y_scaler = StandardScaler()\n",
    "        self.y = self.y[:, np.newaxis]\n",
    "        self.x_scaler.fit(self.x)\n",
    "        self.y_scaler.fit(self.y)\n",
    "        self.x = self.x_scaler.transform(self.x)\n",
    "        self.y = self.y_scaler.transform(self.y)\n",
    "        self.y = np.reshape(self.y, self.y.shape[0])\n",
    "\n",
    "\n",
    "    def read_csv(self, path):\n",
    "        self.data = pd.read_csv(path, dtype = np.float64).to_numpy()\n",
    "        try:\n",
    "            self.p = self.data.shape[1] - 1\n",
    "            self.m = self.data.shape[0]\n",
    "        except:\n",
    "            logging.error(f\"Input needs to have at least two dimensions. Input dimension was {self.data.shape}\")\n",
    "            raise ValueError\n",
    "\n",
    "        self.x = self.data[:, [x for x in range(self.p)]]\n",
    "        self.y = self.data[:, self.p]\n",
    "\n",
    "\n",
    "    def add_ones_to_x(self):\n",
    "        self.x = np.concatenate((np.ones([self.m, 1], dtype = self.x.dtype), self.x), axis = 1)\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.x[i], self.y[i])\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.data.shape[0])\n",
    "\n",
    "    \n",
    "    def __iter__(self):\n",
    "        self.i = -1\n",
    "        return (self)\n",
    "\n",
    "\n",
    "    def __next__(self):\n",
    "        self.i += 1\n",
    "        if (self.i < len(self)):\n",
    "            return self[self.i]\n",
    "        else:\n",
    "            self.i = -1\n",
    "            raise StopIteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "float_formatter = \"{:.2E}\".format\n",
    "np.set_printoptions(formatter={'float_kind':float_formatter})\n",
    "from datetime import datetime\n",
    "\n",
    "def normalize(a):\n",
    "    col_sums = a.sum(axis=0)\n",
    "    new_matrix = a / col_sums[np.newaxis, :]\n",
    "    return new_matrix\n",
    "\n",
    "class Shaman():\n",
    "    def __init__(self, dataset):\n",
    "        self.p = dataset.p\n",
    "        self.dataset = dataset\n",
    "        self.thetas = np.zeros([self.p + 1], dtype = float)\n",
    "        self.old_thetas = self.thetas\n",
    "        self.lr = 1.0\n",
    "        self.lr_decay = 1.0 / 2\n",
    "        self.mininal_improvement = 1.0 / 1000\n",
    "        self.oldcost = 0.0\n",
    "        self.c = 1.0 / 2\n",
    "        self.lr_increase = 1.5\n",
    "        self.start_time = None\n",
    "        self.time_limit = 2\n",
    "\n",
    "    def time_stop(self):\n",
    "        return ((datetime.now() - self.start_time).seconds >= 2)\n",
    "\n",
    "    def predict(self, data, thetas = None):\n",
    "        if thetas is None:\n",
    "            thetas = self.thetas\n",
    "        return (np.dot(data, thetas))\n",
    "\n",
    "\n",
    "    def error(self, thetas = None):\n",
    "        if thetas is None:\n",
    "            thetas = self.thetas\n",
    "        predictions = self.predict(self.dataset.x, thetas)\n",
    "        error = predictions - self.dataset.y\n",
    "        return (error)\n",
    "\n",
    "\n",
    "    def mean_squared_error(self, thetas = None):\n",
    "        if thetas is None:\n",
    "            thetas = self.thetas   \n",
    "        squared_error = np.square(self.error(thetas))\n",
    "        return (np.mean(squared_error) / 2)\n",
    "\n",
    "\n",
    "    def compute_gradients(self):\n",
    "        error = self.error()\n",
    "        gradients = np.dot(error, self.dataset.x)\n",
    "        gradients = gradients / len(self.dataset.y)\n",
    "        return (gradients)\n",
    "\n",
    "\n",
    "    def ajimo_goldstein_condition(self, l2_grad_squared, gradients, lr):\n",
    "        thetas = self.thetas - lr * gradients\n",
    "        cost = self.mean_squared_error(thetas)\n",
    "        objective = self.newcost - (self.c * lr * l2_grad_squared)\n",
    "        return (cost <= objective)\n",
    "\n",
    "\n",
    "    def ajimo(self, gradients):\n",
    "        l2_grad_squared = np.square(gradients).sum()\n",
    "        lr = self.lr * self.lr_increase\n",
    "        while (not self.ajimo_goldstein_condition(l2_grad_squared, gradients, lr)):\n",
    "            lr = lr * self.lr_decay\n",
    "        self.lr = lr\n",
    "\n",
    "    def update_thetas(self):\n",
    "        self.old_thetas = self.thetas\n",
    "        gradients = self.compute_gradients()\n",
    "        self.ajimo(gradients)\n",
    "        self.thetas = self.thetas - (self.lr * gradients)\n",
    "\n",
    "    \n",
    "    def update_costs(self):\n",
    "        tmpold = self.oldcost\n",
    "        self.oldcost = self.newcost\n",
    "        self.newcost = self.mean_squared_error()\n",
    "        return tmpold\n",
    "\n",
    "\n",
    "    def undo_update_costs(self, tmpold):\n",
    "        self.newcost =self.oldcost\n",
    "        self.oldcost = tmpold\n",
    "\n",
    "\n",
    "    def training_loop(self):\n",
    "        self.start_time = datetime.now()\n",
    "        self.newcost = self.mean_squared_error()\n",
    "        while (not self.time_stop()):\n",
    "            tmpold = self.oldcost\n",
    "            self.update_thetas()\n",
    "            tmpold = self.update_costs()\n",
    "            if (self.newcost > self.oldcost):\n",
    "                print(\"lol\")\n",
    "                self.lr = self.lr * self.lr_decay\n",
    "                self.thetas = self.old_thetas\n",
    "                self.undo_update_costs(tmpold)\n",
    "\n",
    "\n",
    "    def middle_error(self):\n",
    "        middle_thetas = (self.thetas + self.old_thetas) / 2\n",
    "        return self.mean_squared_error(middle_thetas)\n",
    "\n",
    "    \n",
    "    def should_i_stop(self):\n",
    "        if abs(self.oldcost - self.newcost) > self.mininal_improvement:\n",
    "            return False\n",
    "        if abs(self.middle_error() - self.newcost) > self.mininal_improvement:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "\n",
    "    def unstandardize_thetas(self):\n",
    "        self.thetas[1:] = self.thetas[1:] / self.dataset.x_scaler.scale_\n",
    "        self.thetas[0] = self.thetas[0] - np.dot(self.thetas[1:], self.dataset.x_scaler.mean_)\n",
    "        self.thetas = self.thetas * self.dataset.y_scaler.scale_\n",
    "        self.thetas[0] += self.dataset.y_scaler.mean_\n",
    "\n",
    "\n",
    "    def write_thetas_to_file(self, filename=\"thetas.csv\"):\n",
    "        self.unstandardize_thetas()\n",
    "        with open(filename, \"w+\") as file:\n",
    "            file.write(\",\".join([str(x) for x in self.thetas]))\n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "        return (f\"Cost: {self.newcost}, Thetas: {self.thetas}, LR {self.lr:4.2E}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Current Time = 13:28:14\n",
      "Current Time = 13:28:16\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "d = Dataset(\"Fish.csv\")\n",
    "shaman = Shaman(d)\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)\n",
    "shaman.training_loop()\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)\n",
    "shaman.write_thetas_to_file()\n",
    "# # shaman.predict(d.x[0])\n",
    "# shaman.predict(d.x)\n",
    "# print(shaman)\n",
    "# shaman.update_thetas(d)\n",
    "# print(shaman)\n",
    "# shaman.compute_gradients(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Dataset(\"data/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1.00E+00 2.40E+05]\n [1.00E+00 1.40E+05]\n [1.00E+00 1.50E+05]\n [1.00E+00 1.86E+05]\n [1.00E+00 1.76E+05]\n [1.00E+00 1.15E+05]\n [1.00E+00 1.67E+05]\n [1.00E+00 8.90E+04]\n [1.00E+00 1.44E+05]\n [1.00E+00 8.40E+04]\n [1.00E+00 8.20E+04]\n [1.00E+00 6.31E+04]\n [1.00E+00 7.40E+04]\n [1.00E+00 9.75E+04]\n [1.00E+00 6.70E+04]\n [1.00E+00 7.60E+04]\n [1.00E+00 4.82E+04]\n [1.00E+00 9.30E+04]\n [1.00E+00 6.09E+04]\n [1.00E+00 6.57E+04]\n [1.00E+00 5.40E+04]\n [1.00E+00 6.85E+04]\n [1.00E+00 2.29E+04]\n [1.00E+00 6.18E+04]] [3.65E+03 3.80E+03 4.40E+03 4.45E+03 5.25E+03 5.35E+03 5.80E+03 5.99E+03\n 6.00E+03 6.20E+03 6.39E+03 6.39E+03 6.60E+03 6.80E+03 6.80E+03 6.90E+03\n 6.90E+03 6.99E+03 7.49E+03 7.56E+03 7.99E+03 7.99E+03 7.99E+03 8.29E+03]\n"
     ]
    }
   ],
   "source": [
    "d.destandardize()\n",
    "print(d.x, d.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cost: 0.028371475606962415, Thetas: [7.22E-16 2.78E-01 3.36E-01 -4.21E-01 6.03E-01 1.97E-01], LR 1.95E-09\n(225, 242)\n(307, 290)\n(327, 340)\n(369, 363)\n(382, 430)\n(447, 450)\n(508, 500)\n(385, 390)\n(478, 450)\n(502, 500)\n(517, 475)\n(512, 500)\n(458, 500)\n(505, 340)\n(578, 600)\n(632, 600)\n(589, 700)\n(585, 700)\n(641, 610)\n(600, 650)\n(630, 575)\n(682, 685)\n(647, 620)\n(686, 680)\n(709, 700)\n(733, 725)\n(745, 720)\n(751, 714)\n(794, 850)\n(958, 1000)\n(902, 920)\n(906, 955)\n(985, 925)\n(1011, 975)\n(922, 950)\n"
     ]
    }
   ],
   "source": [
    "print(shaman)\n",
    "float_formatter = \"{:.0f}\".format\n",
    "np.set_printoptions(formatter={'float_kind':float_formatter})\n",
    "for x, y in shaman.dataset:\n",
    "    print(f\"{int(d.y_scaler.inverse_transform([shaman.predict(x)])[0]), int(d.y_scaler.inverse_transform([y])[0])}\")\n",
    "\n",
    "# print(np.mean(np.square([d.y_scaler.inverse_transform([shaman.predict(x)]) - d.y_scaler.inverse_transform([y])for x, y in shaman.dataset])))\n",
    "#     # print(f\"{shaman.predict(x)}\\t {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([2.26E+02, 3.07E+02, 3.27E+02, 3.69E+02, 3.82E+02, 4.47E+02,\n",
       "       5.09E+02, 3.86E+02, 4.78E+02, 5.03E+02, 5.17E+02, 5.13E+02,\n",
       "       4.59E+02, 5.05E+02, 5.78E+02, 6.33E+02, 5.90E+02, 5.85E+02,\n",
       "       6.41E+02, 6.00E+02, 6.30E+02, 6.82E+02, 6.47E+02, 6.87E+02,\n",
       "       7.09E+02, 7.33E+02, 7.45E+02, 7.52E+02, 7.95E+02, 9.59E+02,\n",
       "       9.02E+02, 9.07E+02, 9.86E+02, 1.01E+03, 9.22E+02])"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "# shaman.dataset.x[:,1:] = shaman.dataset.x_scaler.inverse_transform(shaman.dataset.x[:,1:])\n",
    "shaman.predict(shaman.dataset.x)\n",
    "# shaman.unstandardize_thetas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([-9.39E+02, 1.62E+01, 1.80E+01, -2.12E+01, 6.42E+01, 5.71E+01])"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "shaman.thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([8.50E+03, -2.14E-02])"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "np.genfromtxt('thetas.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "shaman.thetas[1:] = shaman.thetas[1:] / shaman.dataset.x_scaler.scale_\n",
    "shaman.thetas[0] = shaman.thetas[0] - np.dot(shaman.thetas[1:], shaman.dataset.x_scaler.mean_)\n",
    "shaman.thetas = shaman.thetas * shaman.dataset.y_scaler.scale_\n",
    "shaman.thetas[0] += shaman.dataset.y_scaler.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "225.8156460509479"
      ]
     },
     "metadata": {},
     "execution_count": 97
    }
   ],
   "source": [
    "shaman.predict([1,23.2,25.4,30,11.52,4.02])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}