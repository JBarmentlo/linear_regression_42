{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitbaseconda6a1770027b924823bf65f396110ad90f",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "bc4fbd6e1bea1fda9411923f753f92d3282c070fdbd959891bf5a78b35520a26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "\n",
    "class Datapoint():\n",
    "    def __init__(self, km, price):\n",
    "        self.km = km\n",
    "        self.price = price\n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "        return (f\"km: {self.km}, price {self.price}\")\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (f\"km: {self.km}, price {self.price}\")\n",
    "\n",
    "class Dataset():\n",
    "    def __init__(self, path):\n",
    "        self.data = None\n",
    "        self.i = -1\n",
    "        self.read_csv(path)\n",
    "\n",
    "\n",
    "    def read_csv(self, path):\n",
    "        self.data = pd.read_csv(path).to_numpy()\n",
    "        try:\n",
    "            self.p = self.data.shape[1] - 1\n",
    "            self.m = self.data.shape[0]\n",
    "        except:\n",
    "            logging.error(f\"Input needs to have at least two dimensions. Input dimension was {self.data.shape}\")\n",
    "            raise ValueError\n",
    "\n",
    "        self.x = self.data[:, [x for x in range(self.p)]]\n",
    "        self.x = np.concatenate((np.ones([self.m, 1], dtype = self.x.dtype), self.x), axis = 1)\n",
    "        self.y = self.data[:, self.p]\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.x[i], self.y[i])\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.data.shape[0])\n",
    "\n",
    "    \n",
    "    def __iter__(self):\n",
    "        self.i = -1\n",
    "        return (self)\n",
    "\n",
    "    def __next__(self):\n",
    "        self.i += 1\n",
    "        if (self.i < len(self)):\n",
    "            return self[self.i]\n",
    "        else:\n",
    "            self.i = -1\n",
    "            raise StopIteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "float_formatter = \"{:.2E}\".format\n",
    "np.set_printoptions(formatter={'float_kind':float_formatter})\n",
    "\n",
    "def normalize(a):\n",
    "    col_sums = a.sum(axis=0)\n",
    "    new_matrix = a / col_sums[np.newaxis, :]\n",
    "    return new_matrix\n",
    "\n",
    "class Shaman():\n",
    "    def __init__(self, dataset):\n",
    "        self.p = dataset.p\n",
    "        self.dataset = dataset\n",
    "        self.thetas = np.zeros([self.p + 1], dtype = float)\n",
    "        self.old_thetas = self.thetas\n",
    "        self.lr = 1.0\n",
    "        self.lr_decay = 1.0 / 2\n",
    "        self.mininal_improvement = 0.1\n",
    "        self.newcost = 0.0\n",
    "        self.oldcost = 0.0\n",
    "        self.c = 1.0 / 2\n",
    "        self.tau = 1.0 / 2\n",
    "\n",
    "\n",
    "    def predict(self, data, thetas = None):\n",
    "        if thetas is None:\n",
    "            thetas = self.thetas\n",
    "        return (np.dot(data, thetas))\n",
    "\n",
    "\n",
    "    def error(self, thetas = None):\n",
    "        if thetas is None:\n",
    "            thetas = self.thetas\n",
    "        predictions = self.predict(self.dataset.x, thetas)\n",
    "        error = predictions - self.dataset.y\n",
    "        return (error)\n",
    "\n",
    "\n",
    "    def mean_squared_error(self, thetas = None):\n",
    "        if thetas is None:\n",
    "            thetas = self.thetas   \n",
    "        squared_error = np.square(self.error(thetas))\n",
    "        return (np.mean(squared_error) / 2)\n",
    "\n",
    "\n",
    "    def compute_gradients(self):\n",
    "        error = self.error()\n",
    "        gradients = np.dot(error, normalize(self.dataset.x))\n",
    "        gradients = gradients / len(self.dataset.y)\n",
    "        return (gradients)\n",
    "\n",
    "\n",
    "    def update_thetas(self):\n",
    "        self.old_thetas = self.thetas\n",
    "        self.thetas = self.thetas - (self.lr * self.compute_gradients())\n",
    "\n",
    "    \n",
    "    def update_costs(self):\n",
    "        tmpold = self.oldcost\n",
    "        self.oldcost = self.newcost\n",
    "        self.newcost = self.mean_squared_error()\n",
    "        return tmpold\n",
    "\n",
    "\n",
    "    def undo_update_costs(self, tmpold):\n",
    "        self.newcost =self.oldcost\n",
    "        self.oldcost = tmpold\n",
    "\n",
    "\n",
    "    def training_loop(self):\n",
    "        keep_learning = True\n",
    "        self.newcost = self.mean_squared_error()\n",
    "        while (keep_learning):\n",
    "            tmpold = self.oldcost\n",
    "            self.update_thetas()\n",
    "            tmpold = self.update_costs()\n",
    "            if (self.newcost > self.oldcost):\n",
    "                self.lr = self.lr * self.lr_decay\n",
    "                self.thetas = self.old_thetas\n",
    "                self.undo_update_costs(tmpold)\n",
    "            keep_learning = not self.should_i_stop()\n",
    "            print(self)\n",
    "\n",
    "\n",
    "    def middle_error(self):\n",
    "        middle_thetas = (self.thetas + self.old_thetas) / 2\n",
    "        return self.mean_squared_error(middle_thetas)\n",
    "\n",
    "    \n",
    "    def should_i_stop(self):\n",
    "        if abs(self.oldcost - self.newcost) > self.mininal_improvement:\n",
    "            return False\n",
    "        if abs(self.middle_error() - self.newcost) > self.mininal_improvement:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "\n",
    "    def ajimo(self, gradients):\n",
    "        l2_grad_squared = np.square(gradients).sum()\n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "        return (f\"Cost: {self.newcost:.2e}, Thetas: {self.thetas}, LR {self.lr:4.2E}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ".80e+06, Thetas: [5.16E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.16E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.16E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.16E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.16E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.16E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.16E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.16E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.16E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.16E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.16E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.16E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.16E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.16E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.17E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.18E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.19E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.20E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.21E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.22E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.22E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.22E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.22E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.22E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.22E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.22E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.22E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.22E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.22E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.22E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.22E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.22E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.22E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.22E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.22E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.22E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.22E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.22E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.22E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.22E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.22E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.22E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.22E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.22E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.22E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.22E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.22E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.22E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.22E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.22E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.22E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.22E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.22E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.22E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.22E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.22E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.22E+02 4.12E-02], LR 2.44E-04\n",
      "Cost: 6.80e+06, Thetas: [5.22E+02 4.12E-02], LR 2.44E-04\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-4206d644fd2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mshaman\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mShaman\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mshaman\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# shaman.predict(d.x[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# shaman.predict(d.x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-5115155b1024>\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mtmpold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moldcost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_thetas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mtmpold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_costs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewcost\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moldcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_decay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-5115155b1024>\u001b[0m in \u001b[0;36mupdate_costs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mtmpold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moldcost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moldcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewcost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtmpold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-5115155b1024>\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(self, thetas)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mthetas\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mthetas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthetas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0msquared_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthetas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msquared_error\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-5115155b1024>\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, thetas)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mthetas\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mthetas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthetas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthetas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "d = Dataset(\"data.csv\")\n",
    "shaman = Shaman(d)\n",
    "shaman.training_loop()\n",
    "# shaman.predict(d.x[0])\n",
    "# shaman.predict(d.x)\n",
    "# print(shaman)\n",
    "# shaman.update_thetas(d)\n",
    "# print(shaman)\n",
    "# shaman.compute_gradients(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = np.ones([2], dtype = float)\n",
    "ones[0] = 2\n",
    "twos = ones * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.04166667, 0.098945  ],\n",
       "       [0.04166667, 0.05763546],\n",
       "       [0.04166667, 0.06204676],\n",
       "       [0.04166667, 0.07648861],\n",
       "       [0.04166667, 0.07255967],\n",
       "       [0.04166667, 0.04732869],\n",
       "       [0.04166667, 0.06876677],\n",
       "       [0.04166667, 0.0366921 ],\n",
       "       [0.04166667, 0.05957313],\n",
       "       [0.04166667, 0.03463075],\n",
       "       [0.04166667, 0.03381816],\n",
       "       [0.04166667, 0.0259978 ],\n",
       "       [0.04166667, 0.03050804],\n",
       "       [0.04166667, 0.04019641],\n",
       "       [0.04166667, 0.02762215],\n",
       "       [0.04166667, 0.03134289],\n",
       "       [0.04166667, 0.01988588],\n",
       "       [0.04166667, 0.03834119],\n",
       "       [0.04166667, 0.02512749],\n",
       "       [0.04166667, 0.02707547],\n",
       "       [0.04166667, 0.02226262],\n",
       "       [0.04166667, 0.02824055],\n",
       "       [0.04166667, 0.00944059],\n",
       "       [0.04166667, 0.0254738 ]])"
      ]
     },
     "metadata": {},
     "execution_count": 195
    }
   ],
   "source": [
    "normalize(d.x)\n",
    "# d.x / d.x.sum(axis=0)[np.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = np.array([1,2,3,4])\n",
    "inputs = np.array([[1,2,3], [2,2,2], [3,3,3], [4,4,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1 2 3 4]\n\n\n[[1 2 3]\n [2 2 2]\n [3 3 3]\n [4 4 4]]\n"
     ]
    }
   ],
   "source": [
    "print(e)\n",
    "print(\"\\n\")\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([30, 31, 32])"
      ]
     },
     "metadata": {},
     "execution_count": 140
    }
   ],
   "source": [
    "np.dot(e, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[     1 240000]\n [     1 139800]\n [     1 150500]\n [     1 185530]\n [     1 176000]\n [     1 114800]\n [     1 166800]\n [     1  89000]\n [     1 144500]\n [     1  84000]\n [     1  82029]\n [     1  63060]\n [     1  74000]\n [     1  97500]\n [     1  67000]\n [     1  76025]\n [     1  48235]\n [     1  93000]\n [     1  60949]\n [     1  65674]\n [     1  54000]\n [     1  68500]\n [     1  22899]\n [     1  61789]]\n"
     ]
    }
   ],
   "source": [
    "print(d.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}