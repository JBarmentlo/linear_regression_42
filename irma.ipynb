{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0bc4fbd6e1bea1fda9411923f753f92d3282c070fdbd959891bf5a78b35520a26",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "bc4fbd6e1bea1fda9411923f753f92d3282c070fdbd959891bf5a78b35520a26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "\n",
    "class Datapoint():\n",
    "    def __init__(self, km, price):\n",
    "        self.km = km\n",
    "        self.price = price\n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "        return (f\"km: {self.km}, price {self.price}\")\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (f\"km: {self.km}, price {self.price}\")\n",
    "\n",
    "class Dataset():\n",
    "    def __init__(self, path):\n",
    "        self.data = None\n",
    "        self.i = -1\n",
    "        self.read_csv(path)\n",
    "\n",
    "\n",
    "    def read_csv(self, path):\n",
    "        self.data = pd.read_csv(path).to_numpy()\n",
    "        try:\n",
    "            self.p = self.data.shape[1] - 1\n",
    "            self.m = self.data.shape[0]\n",
    "        except:\n",
    "            logging.error(f\"Input needs to have at least two dimensions. Input dimension was {self.data.shape}\")\n",
    "            raise ValueError\n",
    "\n",
    "        self.x = self.data[:, [x for x in range(self.p)]]\n",
    "        self.x = np.concatenate((np.ones([self.m, 1], dtype = self.x.dtype), self.x), axis = 1)\n",
    "        self.y = self.data[:, self.p]\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.x[i], self.y[i])\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.data.shape[0])\n",
    "\n",
    "    \n",
    "    def __iter__(self):\n",
    "        self.i = -1\n",
    "        return (self)\n",
    "\n",
    "    def __next__(self):\n",
    "        self.i += 1\n",
    "        if (self.i < len(self)):\n",
    "            return self[self.i]\n",
    "        else:\n",
    "            self.i = -1\n",
    "            raise StopIteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "float_formatter = \"{:.2E}\".format\n",
    "np.set_printoptions(formatter={'float_kind':float_formatter})\n",
    "\n",
    "def normalize(a):\n",
    "    col_sums = a.sum(axis=0)\n",
    "    new_matrix = a / col_sums[np.newaxis, :]\n",
    "    return new_matrix\n",
    "\n",
    "class Shaman():\n",
    "    def __init__(self, dataset):\n",
    "        self.p = dataset.p\n",
    "        self.thetas = np.zeros([self.p + 1], dtype = float)\n",
    "        self.old_thetas = self.thetas\n",
    "        self.lr = 1.0\n",
    "        self.lr_decay = 1.0 / 2\n",
    "        self.mininal_improvement = 0.1\n",
    "        self.newcost = 0.0\n",
    "        self.oldcost = 0.0\n",
    "\n",
    "\n",
    "    def predict(self, data, thetas = None):\n",
    "        if thetas is None:\n",
    "            thetas = self.thetas\n",
    "        return (np.dot(data, thetas))\n",
    "\n",
    "\n",
    "    def error(self, dataset, thetas = None):\n",
    "        if thetas is None:\n",
    "            thetas = self.thetas\n",
    "        predictions = self.predict(dataset.x, thetas)\n",
    "        error = predictions - dataset.y\n",
    "        return (error)\n",
    "\n",
    "\n",
    "    def mean_squared_error(self, dataset, thetas = None):\n",
    "        if thetas is None:\n",
    "            thetas = self.thetas   \n",
    "        squared_error = np.square(self.error(dataset, thetas))\n",
    "        return (np.mean(squared_error))\n",
    "\n",
    "\n",
    "    def compute_gradients(self, dataset):\n",
    "        error = self.error(dataset)\n",
    "        gradients = np.dot(error, normalize(dataset.x))\n",
    "        gradients = gradients / len(dataset.y)\n",
    "        return (gradients)\n",
    "\n",
    "\n",
    "    def update_thetas(self, dataset):\n",
    "        self.old_thetas = self.thetas\n",
    "        self.thetas = self.thetas - (self.lr * self.compute_gradients(dataset))\n",
    "\n",
    "    \n",
    "    def update_costs(self, dataset):\n",
    "        tmpold = self.oldcost\n",
    "        self.oldcost = self.newcost\n",
    "        self.newcost = self.mean_squared_error(dataset)\n",
    "        return tmpold\n",
    "\n",
    "\n",
    "    def undo_update_costs(self, tmpold):\n",
    "        self.newcost =self.oldcost\n",
    "        self.oldcost = tmpold\n",
    "\n",
    "\n",
    "    def training_loop(self, dataset):\n",
    "        keep_learning = True\n",
    "        self.newcost = self.mean_squared_error(dataset)\n",
    "        while (keep_learning):\n",
    "            tmpold = self.oldcost\n",
    "            self.update_thetas(dataset)\n",
    "            tmpold = self.update_costs(dataset)\n",
    "            if (self.newcost > self.oldcost):\n",
    "                self.lr = self.lr * self.lr_decay\n",
    "                self.thetas = self.old_thetas\n",
    "                self.undo_update_costs(tmpold)\n",
    "            keep_learning = not self.should_i_stop(dataset)\n",
    "            print(self)\n",
    "\n",
    "\n",
    "    def middle_error(self, dataset):\n",
    "        middle_thetas = (self.thetas + self.old_thetas) / 2\n",
    "        return self.mean_squared_error(dataset, middle_thetas)\n",
    "\n",
    "    \n",
    "    def should_i_stop(self, dataset):\n",
    "        if abs(self.oldcost - self.newcost) > self.mininal_improvement:\n",
    "            return False\n",
    "        if abs(self.middle_error(dataset) - self.newcost) > self.mininal_improvement:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "        return (f\"Cost: {self.newcost:.2e}, Thetas: {self.thetas}, LR {self.lr:4.2E}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "8.82e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.82e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.82e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.82e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.82e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.82e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.82e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.82e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.82e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.82e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.82e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.82e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.82e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.82e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.82e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.82e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.82e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.82e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.82e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.82e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.82e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.82e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.82e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.82e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.82e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.82e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.82e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.82e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.82e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.82e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.82e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.82e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.82e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.82e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.82e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.82e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.82e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.82e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.82e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.82e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.82e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.82e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.13E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.81e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.80e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.80e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.80e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.80e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.80e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.80e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.80e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.80e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.80e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.80e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.80e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.80e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.80e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.80e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.80e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.80e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.80e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.80e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.80e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.80e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.80e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.80e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.80e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04\n",
      "Cost: 8.80e+06, Thetas: [2.14E+03 2.85E-02], LR 2.44E-04"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-249-0a3d15b147ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mshaman\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mShaman\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mshaman\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# shaman.predict(d.x[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# shaman.predict(d.x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-248-91ceec8a6750>\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mundo_update_costs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmpold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mkeep_learning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_i_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0;31m# mp.Pool cannot be trusted to flush promptly (or ever),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# wake event thread (message content is ignored)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    503\u001b[0m                 )\n\u001b[1;32m    504\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSocket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_parts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "d = Dataset(\"data.csv\")\n",
    "shaman = Shaman(d)\n",
    "shaman.training_loop(d)\n",
    "# shaman.predict(d.x[0])\n",
    "# shaman.predict(d.x)\n",
    "# print(shaman)\n",
    "# shaman.update_thetas(d)\n",
    "# print(shaman)\n",
    "# shaman.compute_gradients(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = np.ones([2], dtype = float)\n",
    "ones[0] = 2\n",
    "twos = ones * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.04166667, 0.098945  ],\n",
       "       [0.04166667, 0.05763546],\n",
       "       [0.04166667, 0.06204676],\n",
       "       [0.04166667, 0.07648861],\n",
       "       [0.04166667, 0.07255967],\n",
       "       [0.04166667, 0.04732869],\n",
       "       [0.04166667, 0.06876677],\n",
       "       [0.04166667, 0.0366921 ],\n",
       "       [0.04166667, 0.05957313],\n",
       "       [0.04166667, 0.03463075],\n",
       "       [0.04166667, 0.03381816],\n",
       "       [0.04166667, 0.0259978 ],\n",
       "       [0.04166667, 0.03050804],\n",
       "       [0.04166667, 0.04019641],\n",
       "       [0.04166667, 0.02762215],\n",
       "       [0.04166667, 0.03134289],\n",
       "       [0.04166667, 0.01988588],\n",
       "       [0.04166667, 0.03834119],\n",
       "       [0.04166667, 0.02512749],\n",
       "       [0.04166667, 0.02707547],\n",
       "       [0.04166667, 0.02226262],\n",
       "       [0.04166667, 0.02824055],\n",
       "       [0.04166667, 0.00944059],\n",
       "       [0.04166667, 0.0254738 ]])"
      ]
     },
     "metadata": {},
     "execution_count": 195
    }
   ],
   "source": [
    "normalize(d.x)\n",
    "# d.x / d.x.sum(axis=0)[np.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = np.array([1,2,3,4])\n",
    "inputs = np.array([[1,2,3], [2,2,2], [3,3,3], [4,4,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1 2 3 4]\n\n\n[[1 2 3]\n [2 2 2]\n [3 3 3]\n [4 4 4]]\n"
     ]
    }
   ],
   "source": [
    "print(e)\n",
    "print(\"\\n\")\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([30, 31, 32])"
      ]
     },
     "metadata": {},
     "execution_count": 140
    }
   ],
   "source": [
    "np.dot(e, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[     1 240000]\n [     1 139800]\n [     1 150500]\n [     1 185530]\n [     1 176000]\n [     1 114800]\n [     1 166800]\n [     1  89000]\n [     1 144500]\n [     1  84000]\n [     1  82029]\n [     1  63060]\n [     1  74000]\n [     1  97500]\n [     1  67000]\n [     1  76025]\n [     1  48235]\n [     1  93000]\n [     1  60949]\n [     1  65674]\n [     1  54000]\n [     1  68500]\n [     1  22899]\n [     1  61789]]\n"
     ]
    }
   ],
   "source": [
    "print(d.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}